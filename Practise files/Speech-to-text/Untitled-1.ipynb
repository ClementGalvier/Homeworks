{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\galvi\\OneDrive\\Documents\\GeneralAssembly\\Homeworks\\Practise files\\Speech-to-text\\Untitled-1.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/galvi/OneDrive/Documents/GeneralAssembly/Homeworks/Practise%20files/Speech-to-text/Untitled-1.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspeech_recognition\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msr\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/galvi/OneDrive/Documents/GeneralAssembly/Homeworks/Practise%20files/Speech-to-text/Untitled-1.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydub\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioSegment\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say again PLZ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# audio file to text:\n",
    "recognizer = sr.Recognizer()\n",
    "recognizer.energy_threshold = 300\n",
    "mic=sr.Microphone()\n",
    "audio_file = sr.AudioFile('wild_kind_short.wav')\n",
    "import time\n",
    "\n",
    "with audio_file as source:\n",
    "    audio_file=recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_file)\n",
    "        print(text)\n",
    "    except sr.UnknownValueError:\n",
    "        print('say again PLZ \\n')\n",
    "    except sr.RequestError:\n",
    "        print('speech service down \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say something \n",
      "\n",
      "ready to record\n",
      "\n",
      "audio captured\n",
      "\n",
      "Singapore\n"
     ]
    }
   ],
   "source": [
    "#microphone to text\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "recognizer.energy_threshold = 300\n",
    "mic=sr.Microphone()\n",
    "import time\n",
    "\n",
    "def audio_recording():\n",
    "    with mic as source:\n",
    "        print('say something \\n')\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print('ready to record\\n')\n",
    "        audio=recognizer.listen(source)\n",
    "        print('audio captured\\n')\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(text)\n",
    "        except sr.UnknownValueError:\n",
    "            print('say again PLZ \\n')\n",
    "        except sr.RequestError:\n",
    "            print('speech service down \\n')\n",
    "time.sleep(3)\n",
    "# while 1:\n",
    "audio_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_gcs(gcs_uri):\n",
    "    \"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "        print(\"Confidence: {}\".format(result.alternatives[0].confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Write my name is Clementand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a04f5bcc4cce45f88f55048bde1d1871ccb10dc4647418ede9299c65043aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
